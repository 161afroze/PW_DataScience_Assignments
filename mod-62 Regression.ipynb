{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3263ea51",
   "metadata": {},
   "source": [
    "## 1)  Explain the difference between simple linear regression and multiple linear regression. Provide anexample of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c78a4",
   "metadata": {},
   "source": [
    "simple linear regressoion : one dependent varialbe and one independent variable\n",
    "    \n",
    "multi linear regression : one dependent variable and multiple independent variable\n",
    "    \n",
    "example of simple linear regression : height of the student is the independet variable and weight is the dependent variable \n",
    "    \n",
    "example of multilinear regresssion : number_of_rooms,size_of_house, are the independent variable and price is the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448ac60",
   "metadata": {},
   "source": [
    "## 2) Discuss the assumptions of linear regression. How can you check whether these assumptions hold ina given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0d53a",
   "metadata": {},
   "source": [
    "\n",
    "Mainly there are 7 assumptions taken while using Linear Regression:\n",
    "- Linear Model\n",
    "- No Multicolinearlity in the data\n",
    "- Homoscedasticity of Residuals or Equal Variances\n",
    "- No Autocorrelation in residuals\n",
    "- Number of observations Greater than the number of predictors\n",
    "- Each observation is unique\n",
    "- Predictors are distributed Normally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a300d",
   "metadata": {},
   "source": [
    "## 3) How do you interpret the slope and intercept in a linear regression model? Provide an example usinga real-world scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a5c25",
   "metadata": {},
   "source": [
    "Interpreting the slope and intercept in a linear regression model is crucial for understanding the relationship between the independent and dependent variables. Here's how you interpret them:\n",
    "\n",
    "1. **Intercept (\\( \\beta_0 \\)):** The intercept represents the value of the dependent variable when all independent variables are set to zero. It indicates the starting point of the regression line on the y-axis.\n",
    "\n",
    "2. **Slope (\\( \\beta_1 \\)):** The slope represents the change in the dependent variable for a one-unit change in the independent variable. It indicates the rate of change of the dependent variable concerning the independent variable.\n",
    "\n",
    "Let's illustrate this with a real-world scenario:\n",
    "\n",
    "**Example: Predicting House Prices**\n",
    "\n",
    "Suppose you want to predict house prices based on their sizes. You collect data on various houses, recording their sizes (in square feet) and prices (in dollars). After performing linear regression analysis, you obtain the following equation:\n",
    "\n",
    "\\[ \\text{Price} = \\beta_0 + \\beta_1 \\times \\text{Size} \\]\n",
    "\n",
    "Where:\n",
    "- \\( \\text{Price} \\) is the predicted house price.\n",
    "- \\( \\text{Size} \\) is the size of the house.\n",
    "- \\( \\beta_0 \\) is the intercept (e.g., $50,000).\n",
    "- \\( \\beta_1 \\) is the slope (e.g., $100 per square foot).\n",
    "\n",
    "**Interpretation:**\n",
    "- **Intercept (\\( \\beta_0 \\)):** In this example, the intercept (\\( \\beta_0 \\)) is $50,000. This means that if a house has zero square feet (which is unrealistic), its price would still be $50,000 according to the model. The intercept represents the baseline price or fixed cost associated with owning a house.\n",
    "  \n",
    "- **Slope (\\( \\beta_1 \\)):** The slope (\\( \\beta_1 \\)) is $100 per square foot. This means that for every one-unit increase in the size of the house (in square feet), the predicted price increases by $100. So, if a house's size increases by 100 square feet, the predicted price would increase by $10,000 (100 * $100).\n",
    "\n",
    "Using these interpretations, you can make predictions about house prices based on their sizes. For example, if you have a house with a size of 1500 square feet, you can plug this value into the equation to predict its price:\n",
    "\n",
    "\\[ \\text{Price} = 50,000 + 100 \\times 1500 = \\$200,000 \\]\n",
    "\n",
    "So, according to the model, a house with a size of 1500 square feet would be predicted to have a price of $200,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf085d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177d1f0a",
   "metadata": {},
   "source": [
    "## 4) Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a0e43",
   "metadata": {},
   "source": [
    "gradient descent is an algorithm that is mainly used for the purpose of optimization \n",
    "\n",
    "in Gradient descent a intial slope and intercept is considred and cost function is calculted \n",
    "\n",
    "then using the convergence alogirthm we derivate the slope and find new slope and intercept \n",
    "\n",
    "through this we reach a final point called as global minima , which is the min error causing point for our model \n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb44c60",
   "metadata": {},
   "source": [
    "Gradient descent is a fundamental optimization algorithm used in machine learning to minimize a function, typically a loss function, by iteratively adjusting the parameters of a model. \n",
    "\n",
    "Here's how it works in simple terms:\n",
    "\n",
    "1. **Understanding the Gradient:**\n",
    "   Imagine you're standing on a mountain and want to reach the lowest point in the valley. The gradient tells you the direction of the steepest descent, or the direction in which you should move to reach the lowest point fastest.\n",
    "\n",
    "2. **Starting Point:**\n",
    "   Initially, you randomly pick a point on the mountain. This point represents the initial values of the parameters of your model.\n",
    "\n",
    "3. **Iterative Descent:**\n",
    "   At each step, you calculate the gradient of the function at your current point. This gradient tells you the direction of the steepest decrease in the function value.\n",
    "\n",
    "4. **Update Parameters:**\n",
    "   You then take a small step in the opposite direction of the gradient to move closer to the minimum point. The size of this step is determined by a parameter called the learning rate, which controls how far you move in each iteration.\n",
    "\n",
    "5. **Repeat:**\n",
    "   You keep repeating this process, recalculating the gradient at each step and updating the parameters accordingly. Each iteration brings you closer to the minimum point of the function.\n",
    "\n",
    "6. **Convergence:**\n",
    "   Eventually, after many iterations, you reach a point where the gradient becomes very small (close to zero). At this point, you have reached a minimum (or a very flat area) of the function.\n",
    "\n",
    "In machine learning, gradient descent is used to train models by minimizing a loss function. The parameters of the model (such as weights in a neural network) are adjusted iteratively using gradient descent to find the optimal values that minimize the difference between the predicted output and the actual output. This process is crucial for training models to make accurate predictions on new data.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a4e8d",
   "metadata": {},
   "source": [
    "## 5)  Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458694be",
   "metadata": {},
   "source": [
    "simple linear regressoion : one dependent varialbe and one independent variable\n",
    "    \n",
    "multi linear regression : one dependent variable and multiple independent variable\n",
    "    \n",
    "simple linear regression has only one slope but in multilinear regression , each varialbe has one different slope value \n",
    "\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa292f",
   "metadata": {},
   "source": [
    "Sure, let's simplify it:\n",
    "\n",
    "**Multiple Linear Regression (MLR):**\n",
    "MLR is like baking a cake using multiple ingredients. You have a recipe (equation) where you mix different amounts of flour, sugar, eggs, and other ingredients (independent variables) to make the cake (dependent variable). Each ingredient affects the outcome, and the recipe (equation) considers all these ingredients together to make predictions.\n",
    "\n",
    "**Simple Linear Regression (SLR):**\n",
    "SLR, on the other hand, is like making a cake using only one ingredient, such as flour. You have a simple recipe (equation) where you mix different amounts of flour to make the cake. Here, you're considering only one ingredient (independent variable) to predict the outcome (dependent variable).\n",
    "\n",
    "**Key Differences:**\n",
    "1. **Number of Ingredients (Variables):**\n",
    "   - MLR uses multiple ingredients (independent variables), while SLR uses only one.\n",
    "\n",
    "2. **Complexity:**\n",
    "   - MLR deals with more complexity because it considers the combined effects of multiple ingredients, whereas SLR is simpler since it focuses on just one ingredient.\n",
    "\n",
    "3. **Prediction Accuracy:**\n",
    "   - MLR often provides more accurate predictions because it considers various factors, while SLR might not capture all the nuances in the relationship between the variables.\n",
    "\n",
    "In simple terms, MLR involves multiple ingredients to make predictions, while SLR involves just one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ffcab",
   "metadata": {},
   "source": [
    "## 6) Explain the concept of multicollinearity in multiple linear regression. How can you detect andaddress this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfb001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0776849c",
   "metadata": {},
   "source": [
    "## 7) Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b09a3",
   "metadata": {},
   "source": [
    "in linear regression only one independent variables but in polynomial regression it can have more than one idependent variables \n",
    "\n",
    "lineare regression has linear relationship \n",
    "\n",
    "polynomial regression has non linear relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381603ba",
   "metadata": {},
   "source": [
    "## 8) What are the advantages and disadvantages of polynomial regression compared to linearregression? In what situations would you prefer to use polynomial regression?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e916953",
   "metadata": {},
   "source": [
    " **Advantages of Polynomial Regression:**\n",
    "\n",
    "1. **Flexibility:** Polynomial regression can capture non-linear relationships between variables, allowing for more flexible modeling compared to linear regression.\n",
    "\n",
    "2. **Better Fit:** It can provide a better fit to the data, especially when the relationship between variables is curvilinear or exhibits patterns that cannot be adequately captured by a linear model.\n",
    "\n",
    "3. **Higher Order Relationships:** Polynomial regression can accommodate higher-order relationships between variables, providing a more nuanced understanding of the data.\n",
    "\n",
    "**Disadvantages of Polynomial Regression:**\n",
    "\n",
    "1. **Overfitting:** With higher-degree polynomials, there's a risk of overfitting, where the model captures noise or random fluctuations in the data rather than true patterns. This can lead to poor generalization to unseen data.\n",
    "\n",
    "2. **Complexity:** Higher-degree polynomial models can be complex and difficult to interpret, making it challenging to understand the underlying relationships between variables.\n",
    "\n",
    "3. **Sensitive to Outliers:** Polynomial regression can be sensitive to outliers, as extreme data points can disproportionately influence the shape of the curve.\n",
    "\n",
    "**When to Use Polynomial Regression:**\n",
    "\n",
    "1. **Curvilinear Relationships:** When the relationship between variables is curvilinear, polynomial regression can provide a better fit than linear regression.\n",
    "\n",
    "2. **Complex Patterns:** In situations where the data exhibits complex patterns that cannot be adequately captured by a linear model, polynomial regression may be preferred.\n",
    "\n",
    "3. **Exploratory Analysis:** Polynomial regression can be useful for exploratory analysis to understand the underlying trends in the data, especially when the relationship between variables is not well understood.\n",
    "\n",
    "4. **Small Data Sets:** In cases where the data set is relatively small and fitting a linear model does not capture the variability in the data, polynomial regression can offer a more flexible approach.\n",
    "\n",
    "Overall, while polynomial regression offers greater flexibility in modeling non-linear relationships, it requires careful consideration of model complexity and the potential for overfitting. It's essential to assess the trade-offs between model complexity and interpretability when deciding whether to use polynomial regression over linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2968133",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
